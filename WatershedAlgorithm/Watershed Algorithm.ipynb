{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Libraries Loaded----\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "\timport numpy as np\n",
    "\timport os\n",
    "\timport warnings\n",
    "\timport cv2\n",
    "\timport matplotlib.pyplot as plt\n",
    "\timport argparse\n",
    "\timport imutils\n",
    "\timport skimage.segmentation\n",
    "\tfrom skimage.feature import peak_local_max\n",
    "\tfrom scipy import ndimage\n",
    "\tprint(\"----Libraries Loaded----\")\n",
    "except:\n",
    "    print(\"----Error Loading Libraries----\")\n",
    "\n",
    "    \n",
    "# Igonre Warnings\n",
    "    \n",
    "DeprecationWarning(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Processing Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image and perform pyramid mean shift filtering for the thresholding step\n",
    "\n",
    "image = cv2.imread(\"Input_image.jpg\")\n",
    "meanshiftedimage = cv2.pyrMeanShiftFiltering(image, 30, 60)\n",
    "\n",
    "# Display the Input Image\n",
    "cv2.imshow(\"Input\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Shifted Image\n",
    "\n",
    "cv2.imshow(\"Mean-Shifted Image\", meanshiftedimage)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the mean shift image to grayscale, then thresholding\n",
    "\n",
    "gray = cv2.cvtColor(meanshiftedimage, cv2.COLOR_BGR2GRAY)\n",
    "thresh = cv2.threshold(gray, 0, 255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU | cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1] \n",
    "''' Use cv2.THRESH_BINARY_INV, cv2.THRESH_OTSU, cv2.THRESH_BINARY, and cv2.THRESH_OTSU accordingly in order to get the objects in\n",
    "    white and background in black.'''\n",
    "\n",
    "cv2.imshow(\"Thresh\", thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Watershed Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24 unique segments\n"
     ]
    }
   ],
   "source": [
    "''' Computing the exact Euclidean distance from every binary\n",
    "    pixel to the nearest zero pixel, then finding peaks in this\n",
    "    distance map'''\n",
    "Euclidean_Distance = ndimage.distance_transform_edt(thresh)\n",
    "Peaks = peak_local_max(Euclidean_Distance, indices=False, min_distance=5,labels=thresh)\n",
    "\n",
    "# Finding Markers using 8-connectivity, then appy the Watershed algorithm\n",
    "markers = ndimage.label(Peaks, structure=np.ones((3, 3)))[0]\n",
    "labels = skimage.segmentation.watershed(-Euclidean_Distance, markers, mask=thresh)\n",
    "print(\"Found {} unique segments\".format(len(np.unique(labels)) - 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the unique labels returned by the Watershed algorithm\n",
    "for label in np.unique(labels):\n",
    "\t# if the label=0, we are checking the 'background' so just ignore it\n",
    "\tif label == 0:\n",
    "\t\tcontinue\n",
    "\n",
    "\t# otherwise, allocate memory for the label region and draw it on the mask\n",
    "\tmask = np.zeros(gray.shape, dtype=\"uint8\")\n",
    "\tmask[labels == label] = 255\n",
    "\n",
    "\t# detect contours in the mask and grab the biggest one\n",
    "\tcnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\tcnts = imutils.grab_contours(cnts)\n",
    "\tc = max(cnts, key=cv2.contourArea)\n",
    "\n",
    "\t# draw a shape(circle) enclosing the object\n",
    "\t((x, y), r) = cv2.minEnclosingCircle(c)\n",
    "\tcv2.circle(image, (int(x), int(y)), int(r), (0, 255, 255), 2)\n",
    "\tcv2.putText(image, \"~{}\".format(label), (int(x) - 10, int(y)),cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "\n",
    "# show the Resultant image\n",
    "image  = cv2.resize(image, (600, 500))\n",
    "cv2.imshow(\"Resultant image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
